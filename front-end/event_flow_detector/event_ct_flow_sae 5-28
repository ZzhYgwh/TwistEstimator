#pragma once

#include <glog/logging.h>
#include <ros/ros.h>
#include <sensor_msgs/Image.h>
#include <dvs_msgs/Event.h>
#include <dvs_msgs/EventArray.h>
#include <image_geometry/pinhole_camera_model.h>

#include "sae.h"
#include "event_flow_detector.h"

class SAEFlowDetector
{
public:
    SAEFlowDetector(ros::NodeHandle& nh_this, EventParams& e_params, RadarEventParams r_params, bool show_events, double smooth, int filter_num = 3, bool ignore_polarity = false, double ratio_inliers = 0.1, double grid_size = 15)
        : nh_this_(nh_this), sensor_width(e_params.resolution[0]), ignore_polarity(ignore_polarity), sae_time(e_params.sae_time),
        sensor_height(e_params.resolution[1]), t1_image_count(e_params.t1_count),  T_re(r_params.T_re), radius(e_params.mesh_size),
        grid_size(grid_size)
        // event_dt(e_params.deltaT), event_t1(e_params.t1), lpf(smooth), lpf_v(smooth), filter_num(filter_num), t2_image_count(e_params.t2_count), ratio_inliers(ratio_inliers), show_events_(show_events) 
        {
            K << e_params.fx, 0, e_params.cx,
                0, e_params.fy, e_params.cy,
                0,0,1;

            K_cv = cv::Mat(3, 3, CV_64F, K.transpose().data()).clone(); // 使用 .clone() 以确保数据独立
            K_cv = K_cv.t();

            // distort_cv = (cv::Mat_<double>(1, 5) << e_params.k1, e_params.k2, e_params.p1, e_params.p2, e_params.k3);
            // LOG(ERROR) << "distort_cv = " << e_params.k1 << " " 
            //                                 << e_params.k2 << " "
            //                                 << e_params.p1 << " " 
            //                                 << e_params.p2 << " " 
            //                                 << e_params.k3 << std::endl;

            image_pub_ = nh_this.advertise<sensor_msgs::Image>("/event/flow_img", 10);  
            pub_event_image_ = nh_this.advertise<sensor_msgs::Image>("/event/img", 10);
            pub_raw_image_ = nh_this.advertise<sensor_msgs::Image>("/dvs/raw_img", 10);

            event_buffer.reserve(100000);
            raw_img_buffer.reserve(100000);
            
            cam_info.height = sensor_height;
            cam_info.width = sensor_width;
            // cam_info.K = K_cv;
            std::copy(K_cv.ptr<double>(), K_cv.ptr<double>() + 9, cam_info.K.begin());

            for (size_t i = 0; i < 9; ++i) {
                LOG(ERROR) << cam_info.K[i] << " ";
            }

            // 直接赋值
            cam_info.distortion_model = "plumb_bob";
            cam_info.D = {e_params.k1, e_params.k2, e_params.p1, e_params.p2, e_params.k3};

            LOG(ERROR) << "Distortion Coefficients: ";
            for (size_t i = 0; i < cam_info.D.size(); i++) {
                LOG(ERROR) << cam_info.D[i] << " ";
            }
            LOG(ERROR) << std::endl;

            // Set P matrix (assuming no stereo calibration)
            cam_info.P[0] = cam_info.K[0];
            cam_info.P[1] = cam_info.K[1];
            cam_info.P[2] = cam_info.K[2];
            cam_info.P[3] = 0.0;
            cam_info.P[4] = cam_info.K[3];
            cam_info.P[5] = cam_info.K[4];
            cam_info.P[6] = cam_info.K[5];
            cam_info.P[7] = 0.0;
            cam_info.P[8] = cam_info.K[6];
            cam_info.P[9] = cam_info.K[7];
            cam_info.P[10] = cam_info.K[8];
            cam_info.P[11] = 0.0;

            // Set R matrix to identity
            cam_info.R[0] = cam_info.R[4] = cam_info.R[8] = 1.0;
            cam_info.R[1] = cam_info.R[2] = cam_info.R[3] = 0.0;
            cam_info.R[5] = cam_info.R[6] = cam_info.R[7] = 0.0;

            // memcpy(cam_info.K.data(), K_cv.ptr<double>(), 9 * sizeof(double));
            camera_model.fromCameraInfo(cam_info);


            cv_image_.encoding = "bgr8"; // 假设处理的是彩色图像
            cv_image_.header.frame_id = "camera_frame";

            // Init SAE
            sae_ptr_ = std::make_shared<SAE>(sensor_width, sensor_height);
        }

    void EventArray2EventVec()
    {
        // std::lock_guard<std::mutex> lock(callback_mutex);
        {
            // LOG(ERROR) << "event_stream.size = " << event_stream.size() << std::endl;
            // 取出事件流的所有事件，避免持锁时间过长
            for (const auto& event_array : event_stream) {
                event_buffer.insert(event_buffer.end(), event_array->events.begin(), event_array->events.end());
            }
            event_stream.clear();
        }
        // LOG(ERROR) << "restore " << event_buffer.size() << std::endl;
    }

    void AccumulateTimeImage()
    {
        for(auto& event : event_buffer)
        {
            sae_ptr_->addEvent(event);  // Note: this is ROS time
        }
    }

    // 构建反对称矩阵
    Eigen::Matrix3d skew(const Eigen::Vector3d& vec) const {
        Eigen::Matrix3d result;
        result << 0, -vec(2), vec(1), vec(2), 0, -vec(0), -vec(1), vec(0), 0;
        return result;
    }

    std::vector<int> RandomSample(int N, int sample_num) {
        std::vector<int> idx(N);
        std::iota(idx.begin(), idx.end(), 0);
        std::random_device rd;
        std::mt19937 g(rd());
        std::shuffle(idx.begin(), idx.end(), g);
        return std::vector<int>(idx.begin(), idx.begin() + sample_num);
    }

    void RansacPlaneFit(const Eigen::MatrixXd& A, double threshold,
                        Eigen::Vector4d& best_normal,
                        int max_iterations = 8) {

        int N = A.rows();
        int max_inlier_count = 0;
        std::vector<int> best_inliers_index;
        best_inliers_index.clear();

        for (int iter = 0; iter < max_iterations; ++iter) {
            auto sample_idx = RandomSample(N, 4);
            Eigen::MatrixXd A_sample(4,4);
            for (int i=0; i<4; ++i)
                A_sample.row(i) = A.row(sample_idx[i]);

            Eigen::JacobiSVD<Eigen::MatrixXd> svd(A_sample, Eigen::ComputeFullV);
            Eigen::Vector4d normal = svd.matrixV().col(3);

            std::vector<int> current_inliers;
            for (int i=0; i<N; ++i) {
                Eigen::Vector4d pt = A.row(i);
                double dist = std::abs(normal.dot(pt)) / normal.head<3>().norm();
                // LOG(ERROR) << "dist = " << dist << std::endl;
                if (dist < threshold)
                    current_inliers.push_back(i);
            }

            if ((int)current_inliers.size() > max_inlier_count) {
                max_inlier_count = current_inliers.size();
                best_inliers_index = current_inliers;
                // best_normal = normal;

                // LOG(ERROR) << "A_sample = " << A_sample << std::endl;
                // LOG(ERROR) << "normal = " << A_sample << std::endl;
                LOG(ERROR) << "max_inlier_count = " << max_inlier_count << std::endl;
            }
        }

        int best_N = best_inliers_index.size();
        Eigen::MatrixXd A_best(best_N,4);
        for (int i=0; i<best_N; ++i)
            A_best.row(i) = A.row(best_inliers_index[i]);
        LOG(ERROR) << "A_best = " << A_best << std::endl;

        Eigen::JacobiSVD<Eigen::MatrixXd> svd(A_best, Eigen::ComputeFullV);
        best_normal = svd.matrixV().col(3);

        LOG(ERROR) << "best_inliers_index.size = " << best_inliers_index.size() << std::endl;
        LOG(ERROR) << "best_normal = " << best_normal.transpose() << std::endl;

        LOG(ERROR) << "fit error = " << A_best * best_normal << std::endl;
    }


        // SAE光流计算示例
        // 输入:
        //   saeTimeSurface: SAE矩阵，类型CV_64FC1，存储像素的最新事件时间戳，单位秒
        //   validTimeThreshold: 时间阈值，超过此时间视为空（跳过）
        //   windowSize: 拟合窗口大小，奇数，比如3或5
        // 输出:
        //   flowX, flowY: 输出光流X和Y分量，大小同saeTimeSurface，CV_64FC1，空白区域填0
        bool ComputeSAEFlow()
        {
            LOG(ERROR) << "radius = " << radius << std::endl;

            CV_Assert(sae_ptr_->GetPostiveImg().type() == CV_64FC1);
            cv::Mat saeTimeSurface = sae_ptr_->GetPostiveImg(); // return a copy img
            cv::Mat sae_decay = sae_ptr_->decaySAE(saeTimeSurface, sae_time); // 0.2 0.5
            // cv::Mat binaryMask = (saeTimeSurface > 0);  // 只要时间戳 > 0 就认为有效
            cv::Mat binaryMask = (sae_decay > 0);  // 只要时间戳 > 0 就认为有效
            // 将边界处的像素设置为 0
            binaryMask.rowRange(0, radius).setTo(0);                              // 顶部
            binaryMask.rowRange(binaryMask.rows - radius, binaryMask.rows).setTo(0); // 底部
            binaryMask.colRange(0, radius).setTo(0);                              // 左侧
            binaryMask.colRange(binaryMask.cols - radius, binaryMask.cols).setTo(0); // 右侧

            binaryMask.convertTo(binaryMask, CV_8U);   // 转成8位图
            cv::Mat kernel = cv::getStructuringElement(cv::MORPH_RECT,
                                                        cv::Size(2 * radius + 1, 2 * radius + 1));
            cv::Mat erodedMask;
            cv::erode(binaryMask, erodedMask, kernel);
            std::vector<cv::Point> candidates;
            cv::findNonZero(erodedMask, candidates);

            // LOG(ERROR) << "sae_decay type: " << sae_decay.type() << std::endl;

            // static long int img_index = 0;
            // cv::imwrite("/home/hao/Desktop/twist_ws/src/TwistEstimator/output/binary_mask_" 
            //                 + std::to_string(img_index) + ".png", binaryMask);
            // cv::imwrite("/home/hao/Desktop/twist_ws/src/TwistEstimator/output/eroded_mask_" 
            //                 + std::to_string(img_index++) + ".png", erodedMask);

            // 按网格均匀提取一定数量的点,然后在saeTimeSurface有效点局部邻阈中拟合平面参数
            // 设置网格间隔，例如 10 像素
            // int grid_size = std::max(candidates.size() * 0.2, 10.0);
            // int grid_size = 8;
            
            // LOG(ERROR) << "grid_size = " << grid_size << std::endl;
            std::vector<cv::Point> sampled_points;

            // 网格采样
            cv::Mat sample_mask = cv::Mat::zeros(erodedMask.size(), CV_8U);
            // 打乱 candidates 顺序（就地乱序）
            std::random_device rd;
            std::mt19937 g(rd());
            std::shuffle(candidates.begin(), candidates.end(), g);
            for (const auto& pt : candidates) {
                int x = pt.x;
                int y = pt.y;
                if (sample_mask.at<uchar>(y / grid_size, x / grid_size) == 0) {
                    sampled_points.emplace_back(pt);
                    sample_mask.at<uchar>(y / grid_size, x / grid_size) = 1;
                }
            }
            LOG(ERROR) << "total.candidate = " << candidates.size() << std::endl;
            LOG(ERROR) << "sampled_points.size = " << sampled_points.size() << std::endl;
            if(sampled_points.size() < 6)
                return false;

            flow_pre_points.clear();
            best_inliers.clear();
            plane_params.clear();
            // 拟合平面
            const int mesh_size = (2 * radius + 1);
            for (const auto& pt : sampled_points) {
                // 构造每个点的 a * x + b * y + c * t + d = 0;
                Eigen::MatrixXd A(mesh_size * mesh_size, 4);
                // double center_timestamp = saeTimeSurface.at<double>(pt.y, pt.x);
                double center_timestamp = sae_decay.at<double>(pt.y, pt.x);
                // LOG(ERROR) << "center_timestamp = " << center_timestamp << std::endl;
                
                int count = 0;
                for (int dy = -radius; dy <= radius; ++dy) {
                    for (int dx = -radius; dx <= radius; ++dx) {
                        // LOG(ERROR) << "dx = " << dx << ", dy = " << dy << std::endl;
                        // LOG(ERROR) << "x = " << pt.x + dx << ", y = " << pt.y + dy << std::endl;
                        // LOG(ERROR) << "timestamp = " << sae_decay.at<double>(pt.y + dy, pt.x + dx) << std::endl;
                        assert(sae_decay.at<double>(pt.y + dy, pt.x + dx) != 0 && "timstamp fault");
                        // A.row(count++) << dx, dy, sae_decay.at<double>(pt.y + dy, pt.x + dx), 1.0;
                        A.row(count++) << dx, dy, sae_decay.at<double>(pt.y + dy, pt.x + dx) - center_timestamp, 1.0;
                        // A.row(count++) << dx, dy, saeTimeSurface.at<double>(pt.y + dy, pt.x + dx), 1.0;
                                                // - center_timestamp, 1.0;
                        // LOG(ERROR) << "saeTimeSurface = " << saeTimeSurface.at<double>(pt.y + dy, pt.x + dx) << std::endl;
                        // LOG(ERROR) << "sae_decay = " << sae_decay.at<double>(pt.y + dy, pt.x + dx) << std::endl;
                    }
                }
                //  LOG(ERROR) << "pt = " << pt.x << ", " << pt.y << std::endl;
                LOG(ERROR) << "A = " << A << std::endl;

                {
                    Eigen::Vector4d normal;
                    normal.setZero();
                    RansacPlaneFit(A, 0.05, normal, 8);
                    const double a_ = normal(0);
                    const double b_ = normal(1);
                    const double c_ = normal(2);

                    if (std::abs(a_) > 1e-6 && std::abs(b_) > 1e-6) {
                        event_flow_velocity flow;
                        flow.x = -c_ / a_;
                        flow.y = -c_ / b_;
                        double flow_norm = std::sqrt(flow.x * flow.x + flow.y * flow.y);
                        LOG(ERROR) << "local flow = " << flow.x << ", " << flow.y;
                        LOG(ERROR) << "flow norm = " << flow_norm;
                        if(flow_norm < 500)
                        {
                            flow_pre_points.push_back(flow);
                            best_inliers.push_back(pt);
                        }
                        plane_params.push_back(normal);
                    }

                }
            }

            LOG(ERROR) << "best_inliers.size() = " << best_inliers.size() << std::endl;

            if(best_inliers.size() < 3)
            {
                LOG(ERROR) << "not enough flow_collect, only: " << best_inliers.size() << std::endl;
                return false;
            }


            // 1. 归一化 saeTimeSurface 到 [0, 255]
            cv::Mat sae_normalized;
            // cv::normalize(saeTimeSurface, sae_normalized, 0, 255, cv::NORM_MINMAX, CV_8UC1);
            cv::normalize(sae_decay, sae_normalized, 0, 255, cv::NORM_MINMAX, CV_8UC1);

            // sae_normalized.copyTo(sae_normalized);

            // sae_normalized = sae_ptr_->decaySAE(saeTimeSurface);

            // 2. 复制为彩色图以便绘制箭头
            cv::Mat sae_color;
            cv::cvtColor(sae_normalized, sae_color, cv::COLOR_GRAY2BGR);

            // 3. 遍历 best_inliers 和 flow_pre_points，绘制光流箭头
            for (size_t i = 0; i < best_inliers.size(); ++i) {
                const cv::Point2d& pt = best_inliers[i];
                const event_flow_velocity& flow = flow_pre_points[i];

                Eigen::Vector3d normal_flow;
                const auto plane = plane_params[i];
                normal_flow <<  plane(0), plane(1), 0.0;
                double norm_flow_2 = normal_flow.norm() * normal_flow.norm(); 
                normal_flow = (- plane(2) * normal_flow / norm_flow_2);
                LOG(ERROR) << "normal_flow.norm() = " << normal_flow.norm() << std::endl;
                
                if(normal_flow.norm() > 60)
                    continue;
                

                // Eigen::Vector3d normal_flow;
                // normal_flow << flow.x, flow.y, 0.0;

                cv::Point2d normal_end_pt(pt.x + 1.0 * std::max(normal_flow(0), 1.0), pt.y + 1.0 * std::max(normal_flow(1),1.0)); // 放大显示箭头
                // cv::arrowedLine(sae_color, pt, normal_end_pt, cv::Scalar(0, 0, 255), 1, cv::LINE_AA, 0, 0.3);
                cv::line(sae_color, pt, normal_end_pt, cv::Scalar(255, 0, 0), 1, cv::LINE_AA);

                // cv::Point2d end_pt(pt.x + flow.x, pt.y + flow.y); // 放大显示箭头
                // // cv::arrowedLine(sae_color, pt, end_pt, cv::Scalar(0, 255, 0), 1, cv::LINE_AA, 0, 0.3);
                // cv::line(sae_color, pt, end_pt, cv::Scalar(0, 255, 0), 1, cv::LINE_AA);
            }

            // 4. 发布图像
            std_msgs::Header header;
            header.stamp = process_time;
            header.frame_id = "event";

            sensor_msgs::ImagePtr msg = cv_bridge::CvImage(header, "bgr8", sae_color).toImageMsg();
            pub_event_image_.publish(msg);

            // static long int img_index = 0;
            // cv::imwrite("/home/hao/Desktop/twist_ws/src/TwistEstimator/output/flow_" 
            //         + std::to_string(img_index++) + ".png", sae_color);

            return true;
        }


        bool NormalAngularVelocityEsti(
            geometry_msgs::TwistWithCovarianceStamped& radar_vel  // 输出，角速度与协方差
        ) 
        { 
            Eigen::Matrix3d K_inv = K.inverse();
            Eigen::Matrix3d R_re = T_re.block(0, 0, 3, 3);

            const int ransac_iter = 15;
            const int minimum_flow = 3;
            int N = flow_pre_points.size();
            LOG(ERROR) << "N = " << N  << std::endl;
            if (N < minimum_flow) {
                std::cerr << "Error: Not enough points for estimation." << std::endl;
                return false;
            }

            linear_vel << radar_vel.twist.twist.linear.x, radar_vel.twist.twist.linear.y, radar_vel.twist.twist.linear.z;
            if(linear_vel.norm() < 1e-6)
            {
                LOG(ERROR) << "radar ego velocity is valid!" << std::endl;
                return false;
            }

            // 先构造全集 A 和 b
            Eigen::MatrixXd A_all(3 * N, 3);
            Eigen::VectorXd b_all(3 * N);
            normal_flows.clear();
            normal_norms.clear();

            for (int i = 0; i < N; ++i) {
                Eigen::Vector3d pixel_coord = K_inv * Eigen::Vector3d(best_inliers[i].x, best_inliers[i].y, 1.0);
                // Eigen::Vector3d pixel_coord = Eigen::Vector3d(best_inliers[i].x, best_inliers[i].y, 1.0);
                Eigen::Matrix3d pixel_skew = skew(pixel_coord);
                Eigen::Vector3d prefix = pixel_skew * R_re * linear_vel;

                // TODO: 这里 flow_pre_points[i] 需要替换为对应的光流向量，假设用x,y临时代替
                // Eigen::Vector3d flow(flow_pre_points[i].x, flow_pre_points[i].y, 0);

                // double& normal_norm = norm_pre_points[i];

                // norm_pre_points.push_back(grad_norm);
                // flow_pre_points.push_back(flow);          

                // Eigen::Vector3d grad;
                // grad << -1.0 / flow(0), -1.0 / flow(1), 0.0;
                // double normal_norm = 1.0 / grad.norm();
                // Eigen::Vector3d normal_flow = grad * normal_norm;

                const auto plane = plane_params[i];
                Eigen::Vector3d norm_grad_vec;
                // double norm_grad = sqrt(plane(0) * plane(0) + plane(1) * plane(1)); //  a* a + b* b
                norm_grad_vec <<  plane(0), plane(1), 0.0;
                double norm_grad = norm_grad_vec.norm();
                norm_grad_vec = norm_grad_vec / norm_grad;     // grad / grad.norm();
                double normal_norm = - plane(2) / norm_grad;
                Eigen::Vector3d flow = normal_norm * norm_grad_vec;

                

                // 上面的像素光流需要转到相机系下光流
                double focal_len_inv = (K_inv(0,0) + K_inv(1,1)) / 2;
                LOG(ERROR) << "focal_len_inv = " << focal_len_inv << std::endl;
                normal_norm *= focal_len_inv;
                LOG(ERROR) << "normal_norm = " << normal_norm << std::endl;
                // 由于内参仅仅是缩放尺寸，因此梯度方向并不改变 norm_grad_vec
                 

                if(normal_norm > 60)
                    continue;

                normal_flows.push_back(norm_grad_vec);
                normal_norms.push_back(normal_norm);

                {
                    LOG(ERROR) << "flow = " << flow << std::endl;
                    // LOG(ERROR) << "grad = " << grad << std::endl;

                    LOG(ERROR) << "normal_flow = " << norm_grad_vec.transpose() << std::endl;
                    LOG(ERROR) << "pixel_skew = " << pixel_skew << std::endl;
                    LOG(ERROR) << "normal_norm = " << normal_norm << std::endl;

                    LOG(ERROR) << "prefix = " << prefix << std::endl;
                }

                // double normal_norm = norm_pre_points[i]; // flow.norm();
                // Eigen::Vector3d normal_flow = flow.normalized();
                // flow.normalized();

                A_all.block<3,3>(3*i, 0) = prefix * norm_grad_vec.transpose() * pixel_skew;
                b_all.segment<3>(3*i) = -1.0 * prefix * normal_norm;

                // A_all.block<3,3>(3*i, 0) = prefix * normal_flow.transpose() * pixel_skew;
                // b_all.segment<3>(3*i) = -1.0 * prefix * normal_norm;
            }

            LOG(ERROR) << "A_all = " << A_all << std::endl;
            LOG(ERROR) << "b_all = " << b_all << std::endl;            

            // RANSAC初始化
            std::random_device rd;
            std::mt19937 gen(rd());
            std::uniform_int_distribution<> dis(0, N - 1);

            double best_error = std::numeric_limits<double>::max();
            std::vector<int> best_inliers_index;
            Eigen::Vector3d best_angular_vec = Eigen::Vector3d::Zero();

            // RANSAC迭代
            for (int iter = 0; iter < ransac_iter; ++iter) {
                std::vector<int> sample_indices;
                while ((int)sample_indices.size() < minimum_flow) {
                    int idx = dis(gen);
                    if (std::find(sample_indices.begin(), sample_indices.end(), idx) == sample_indices.end()) {
                        sample_indices.push_back(idx);
                    }
                }

                Eigen::MatrixXd A_sample(3 * minimum_flow, 3);
                Eigen::VectorXd b_sample(3 * minimum_flow);
                for (int j = 0; j < minimum_flow; ++j) {
                    int idx = sample_indices[j];
                    A_sample.block<3,3>(3*j, 0) = A_all.block<3,3>(3*idx, 0);
                    b_sample.segment<3>(3*j) = b_all.segment<3>(3*idx);
                }

                Eigen::Vector3d angular_vec = A_sample.colPivHouseholderQr().solve(b_sample);

                // 计算内点和误差
                std::vector<int> inliers;
                double error_sum = 0.0;
                for (int i = 0; i < N; ++i) {
                    Eigen::Vector3d residual = A_all.block<3,3>(3*i, 0) * angular_vec - b_all.segment<3>(3*i);
                    double error = residual.norm();
                    // LOG(ERROR) << "error = " << error << std::endl;
                    if (error < 1.5) {  // 阈值可调 0.5
                        inliers.push_back(i);
                        error_sum += error;
                    }
                }

                if ((int)inliers.size() >= best_inliers_index.size()){ // && error_sum < best_error) {
                    best_error = error_sum;
                    best_inliers_index = inliers;
                    best_angular_vec = angular_vec;
                    // LOG(ERROR) << "best_inliers_index = " << best_inliers_index << std::endl;
                }
            }
            // LOG(ERROR) << "best_error = " << best_error << std::endl;
            LOG(ERROR) << "best_inliers.size = " << best_inliers_index.size() << std::endl;

            if (best_inliers_index.empty()) {
                std::cerr << "RANSAC failed to find a good angular velocity." << std::endl;
                best_inliers.clear();
                flow_pre_points.clear();
                return false;
            }

            // 用内点精细求解
            Eigen::MatrixXd A_inliers(3 * best_inliers_index.size(), 3);
            Eigen::VectorXd b_inliers(3 * best_inliers_index.size());
            for (int i = 0; i < (int)best_inliers_index.size(); ++i) {
                int idx = best_inliers_index[i];
                A_inliers.block<3,3>(3*i, 0) = A_all.block<3,3>(3*idx, 0);
                b_inliers.segment<3>(3*i) = b_all.segment<3>(3*idx);
            }
            LOG(ERROR) << "A_inliers = " << A_inliers << std::endl;
            LOG(ERROR) << "b_inliers = " << b_inliers << std::endl;
            Eigen::Vector3d refined_angular_vec = A_inliers.colPivHouseholderQr().solve(b_inliers);
            LOG(ERROR) << "refined_angular_vec = " << refined_angular_vec.transpose() << std::endl;

            // 计算残差和协方差
            Eigen::VectorXd residual = A_inliers * refined_angular_vec - b_inliers;
            double sigma_r_squared = residual.squaredNorm() / (A_inliers.rows() - A_inliers.cols());
            Eigen::Matrix3d covariance_matrix = sigma_r_squared * (A_inliers.transpose() * A_inliers).inverse();

            // 填充输出消息
            radar_vel.twist.twist.angular.x = refined_angular_vec(0);
            radar_vel.twist.twist.angular.y = refined_angular_vec(1);
            radar_vel.twist.twist.angular.z = refined_angular_vec(2);

            // 清空角速度协方差（36维数组，角速度对应下标21开始的3x3块）
            for (int i = 0; i < 36; ++i) radar_vel.twist.covariance[i] = 0.0;
            for (int i = 0; i < 3; ++i) {
                for (int j = 0; j < 3; ++j) {
                    radar_vel.twist.covariance[21 + i*6 + j] = covariance_matrix(i,j);
                }
            }

            // 填充LSQ后的 best_liners
            std::vector<event_flow_velocity> flow_pre_points_lsq(best_inliers_index.size());
            std::vector<cv::Point2d> best_inliers_lsq(best_inliers_index.size());
            for(auto& idx: best_inliers_index)
            {   
                best_inliers_lsq.push_back(best_inliers[idx]);
                flow_pre_points_lsq.push_back(flow_pre_points[idx]);
            }
            best_inliers.clear();
            flow_pre_points.clear();
            best_inliers = best_inliers_lsq;
            flow_pre_points = flow_pre_points_lsq;

            return true;
        }

         
        // 检测主函数
        std::fstream time_file;
        int skip_radar_scan = 0;
        bool Detector() {
            sensor_msgs::PointCloud2 cur_inliers;
            // HAO: 数据交换
            {
                // std::lock_guard<std::mutex> lock(detector_data_mutex);
                // 如果传感器数据不足，返回
                if (radar_doppler_velocity.empty() || event_stream.empty() || radar_inliers.empty())
                { 
                    // LOG(ERROR) << "data is not enough" << std::endl;
                    return false;
                }

                // 数据对齐
                assert(radar_doppler_velocity.size() == radar_inliers.size() && "Doppler is not same as Inliers");

                process_time = radar_doppler_velocity.front().header.stamp;
                // LOG(ERROR) << "process event time = " << process_time << std::endl;

                // 如果事件相机不足，返回, 等待
                // if (event_stream.back()->header.stamp < process_time) {
                if (event_stream.back()->events.back().ts < process_time) {
                    // std::cout << "event data is not new than radar" << std::endl;
                    // LOG(ERROR) << "event data is not new than radar" << std::endl;
                    // event_stream.clear();
                    return false;
                }

                // 事件数据比较新，删除雷达数据  
                // if (event_stream.front()->header.stamp > process_time) {
                if (event_stream.front()->events.front().ts > process_time) {
                    // std::cout << "event data is not new than radar" << std::endl;
                    LOG(ERROR) << "radar data is not new than event" << std::endl;
                    radar_doppler_velocity.pop_front();
                    radar_inliers.pop_front();
                    return false;
                }

                // 筛选区间内的IMU数据
                
                assert(radar_doppler_velocity.front().header.stamp == radar_inliers.front().header.stamp);
                cur_inliers = radar_inliers.front();
                // LOG(ERROR) << "Check Time: " << std::setprecision(8) << process_time.toSec() << ", " << cur_inliers.header.stamp.toSec() << std::endl;
                // 点云数据比较旧，删除点云数据
                /*if (process_time > cur_inliers.header.stamp) {
                    // std::cout << "event data is not new than radar" << std::endl;
                    // LOG(ERROR) << "radar data is not new than event" << std::endl;
                    radar_inliers.pop_front();
                    return false;
                } */     

                twist_ = radar_doppler_velocity.front();    
            }
            

            radar_doppler_velocity.pop_front(); 
            radar_inliers.pop_front();  

            {
                std::chrono::time_point<std::chrono::high_resolution_clock> start_time = std::chrono::high_resolution_clock::now();
                double process_time_sec = process_time.toSec();

                EventArray2EventVec();
                std::chrono::time_point<std::chrono::high_resolution_clock> time1 = std::chrono::high_resolution_clock::now();
                // bool accumu_done = AccumulateTimeImage(); // process_time_sec
                AccumulateTimeImage();
                std::chrono::time_point<std::chrono::high_resolution_clock> time2 = std::chrono::high_resolution_clock::now();
                bool have_flow = false;
                // if(accumu_done)
                    have_flow = ComputeSAEFlow();
                // else
                // {
                    // LOG(ERROR) << "Not enough event data!" << std::endl;
                    // return false;
                // }
                std::chrono::time_point<std::chrono::high_resolution_clock> time3 = std::chrono::high_resolution_clock::now();
                
                
                
                std::chrono::time_point<std::chrono::high_resolution_clock> time4;    
                std::chrono::time_point<std::chrono::high_resolution_clock> time5; 
                // if(!(have_flow && LSQAugularVelocityEsti(twist_)))

                if(!have_flow)
                {
                    LOG(ERROR) << "No flow " << std::endl;
                }

                // 法向光流
                if(!(have_flow && NormalAngularVelocityEsti(twist_)))
                {
                    twist_.twist.twist.angular.x = 0.0f;
                    twist_.twist.twist.angular.y = 0.0f;
                    twist_.twist.twist.angular.z = 0.0f;
                    LOG(ERROR) << "Angular Estimation Failed!" << std::endl;
                    // 角速度不可用,尽保留线速度
                    // return false;

                    // 后端数据不输入
                    best_inliers.clear();
                    flow_pre_points.clear();

                    return false;
                } 
                else
                {
                    LOG(ERROR) << "PublishTimeImages" << std::endl;
                    time4 = std::chrono::high_resolution_clock::now();
                    
                    // PublishTimeImages(TimeImage1, TimeImage1_time);
                    time5 = std::chrono::high_resolution_clock::now();
                }
                // std::chrono::time_point<std::chrono::high_resolution_clock> time4 = std::chrono::high_resolution_clock::now();
                
                // std::chrono::time_point<std::chrono::high_resolution_clock> time5 = std::chrono::high_resolution_clock::now();

                assert(twist_.header.stamp == cur_inliers.header.stamp 
                    && "radar_inliers not valid Or Time is not correct!");

                // INFO_Velocity(twist_);
                // LOG_Velocity(twist_, "/home/hao/Desktop/twist_ws/src/TwistEstimator/output/detector.tum");


                LOG(ERROR) << "Final Debug for flow: " << best_inliers.size() << std::endl;
                twist_result2_.push_back(TwistData2(twist_, cur_inliers, best_inliers, flow_pre_points,
                    normal_flows, normal_norms));
                std::chrono::time_point<std::chrono::high_resolution_clock> end_time = std::chrono::high_resolution_clock::now();

                {
                    std::chrono::duration<double, std::milli> elapsed;
                    elapsed = end_time - start_time;
                    LOG(ERROR) << "Total Time: " << elapsed.count() << std::endl;
                    elapsed = time1 - start_time;
                    LOG(ERROR) << "EventArray2EventVec: " << elapsed.count() << std::endl;
                    elapsed = time2 - time1;
                    LOG(ERROR) << "AccumulateTimeImage: " << elapsed.count() << std::endl;
                    elapsed = time3 - time2;
                    LOG(ERROR) << "CalculateOpFlowPrepointSingleFit: " << elapsed.count() << std::endl;
                    elapsed = time4 - time3;
                    LOG(ERROR) << "LSQAugularVelocityEsti: " << elapsed.count() << std::endl;
                    elapsed = time5 - time4;
                    LOG(ERROR) << "PublishTimeImages: " << elapsed.count() << std::endl;
                }

            }
            return true;
        }


        // TODO: 数据拷贝可以使用指针来进行
        // 获取光流速度
        geometry_msgs::TwistWithCovarianceStamped GetTwist() const {
            return twist_;
        }

        TwistData2 GetTwistData2() {
            TwistData2 twist_result_temp_ = twist_result2_.front();
            twist_result2_.pop_front();
            return twist_result_temp_;          
        }

public:
    std::vector<sensor_msgs::Image::Ptr> raw_img_buffer;
    std::deque<dvs_msgs::EventArray::Ptr> event_stream;
    std::deque<geometry_msgs::TwistWithCovarianceStamped> radar_doppler_velocity;
    std::deque<sensor_msgs::PointCloud2> radar_inliers;
    std::deque<TwistData> twist_result_;

    std::deque<TwistData2> twist_result2_;


private:
    Eigen::Matrix3d K;
    cv::Mat K_cv;
    ros::NodeHandle nh_this_;
    cv_bridge::CvImage cv_image_;           // transport TimeImage

    ros::Publisher image_pub_;
    ros::Publisher pub_event_image_;
    ros::Publisher pub_raw_image_;
    int sensor_width;
    int sensor_height;
    long int t1_image_count;
    bool ignore_polarity;
    Eigen::Matrix4d T_re;
    int radius;
    ros::Time process_time;

    // Input:
    std::vector<dvs_msgs::Event> event_buffer;
    geometry_msgs::TwistWithCovarianceStamped twist_;
    Eigen::Vector3d linear_vel;

    // Output:
    sensor_msgs::CameraInfo cam_info;
    image_geometry::PinholeCameraModel camera_model;
    // std::vector<Eigen::Vector2d> valid_flows;
    std::vector<event_flow_velocity> flow_pre_points;
    std::vector<cv::Point2d> best_inliers;
    std::vector<double> norm_pre_points;
    std::vector<Eigen::Vector4d> plane_params;
    std::vector<Eigen::Vector3d> normal_flows;
    std::vector<double> normal_norms;
    SAE::Ptr sae_ptr_;
    double sae_time;

    double grid_size;

    cv::Mat TimeImage1;

};